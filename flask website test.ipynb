{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip uninstall [options] <package> ...\n",
      "  pip uninstall [options] -r <requirements file> ...\n",
      "\n",
      "no such option: -i\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.35.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.1.99)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.5)\n",
      "Requirement already satisfied: blinker in /usr/lib/python3/dist-packages (1.4)\n",
      "Collecting flask\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.7)\n",
      "Collecting blinker\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: blinker, flask\n",
      "  Attempting uninstall: blinker\n",
      "    Found existing installation: blinker 1.4\n",
      "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -ignore-installed blinker\n",
    "!pip install transformers sentencepiece datasets blinker flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "# Flask app\n",
    "app = Flask(__name__)\n",
    "# Language token mappings\n",
    "LANG_TOKEN_MAPPING = {\n",
    "    'en' : '<en>',\n",
    "    'fil' : '<fil>',\n",
    "    'hi' : '<hi>',\n",
    "    'id' : '<id>',\n",
    "    'ja' : '<ja>', \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicko\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_repo = \"google/mt5-base\"\n",
    "MODEL_PATH = \"./app/models/mt5_translator_best.pt\"\n",
    "# download mt5 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo, legacy=True)\n",
    "\n",
    "# create a dict of the dict\n",
    "special_tokens = { 'additional_special_tokens': list(LANG_TOKEN_MAPPING.values()) }\n",
    "# add special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# download model\n",
    "model= AutoModelForSeq2SeqLM.from_pretrained(model_repo)\n",
    "# Check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Resize the base model to find SSD\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# Get the SSD and load trained model\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessecary Functions to Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizes and numericalizes input string\n",
    "def encode_input_str(text, target_lang, tokenizer, seq_len,\n",
    "                     lang_token_map=LANG_TOKEN_MAPPING):\n",
    "  target_lang_token = lang_token_map[target_lang]\n",
    "\n",
    "  # Tokenize and add special tokens\n",
    "  input_ids = tokenizer.encode(\n",
    "      text = target_lang_token + text,\n",
    "      return_tensors = 'pt',\n",
    "      padding = 'max_length',\n",
    "      truncation = True,\n",
    "      max_length = seq_len)\n",
    "\n",
    "  return input_ids\n",
    "\n",
    "def predict(text, target_lang, tokenizer):\n",
    "    # Encode the input string\n",
    "    input_ids = encode_input_str(text, target_lang, tokenizer, 20)\n",
    "    # Generate the output\n",
    "    output = model.generate(input_ids.to(device), num_beams = 10, max_length = 30)\n",
    "    # Decode the output\n",
    "    translated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the string in japanese\n",
    "a = predict(\"I'm going to mars\", \"hi\", tokenizer)\n",
    "# make sure it is a string\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मुझे यह सुनिश्चित करने के लिए कहा गया कि मैं'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def translate():\n",
    "    return render_template('translate.html')\n",
    "# Define a route for prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def prediction():\n",
    "    data = request.get_json()\n",
    "    text = data['text']\n",
    "    print(text)\n",
    "    target_lang = data['target_lang']\n",
    "    prediction = predict(text, target_lang, tokenizer)\n",
    "    return jsonify({'prediction': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:07] \"GET /style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:13] \"GET /?text=hello&source=en&target=id HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:13] \"GET /style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:37] \"GET /?text=hello+this+is+test&source=en&target=id HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Jul/2024 20:32:37] \"GET /style.css HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "# run the app\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
